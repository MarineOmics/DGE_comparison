---
title: "DGE_comparison"
author: "Sam Bogan"
date: "8/1/2021"
output:
  github_document: default
  html_document:
    toc: true
    toc_depth: 3
---

#Intro to multifactorial RNA-seq models

    Studies of molecular responses to environmental change increasingly employ multifactorial experimental designs. Incorporating multiple developmental stages, stressors, or populations in RNA-seq experiments can better resolve interactions and autocorrelation among these variables, which can critically shape expression, physiology, and performance. However, downstream analyses resulting from mutlifactorial RNA-seq experiments rarely employ multifactorial models, deferring instead to pairwise contrasts of differential expression (DE). One reason many RNA-seq studies do not test for or report model results for predictors such as random effects, time series, or interactions, is that popular DE packages provide limited functionality for fitting multifactorial models. Here we will break down the strengths and limits of several DE packages as they apply to multifactorial study designs, guide users through the process of determining which packages are best suited to certain designs, and provide custom 'in-house' code for more flexibly fitting multifactorial models of gene expression. 

```{r setup, include = FALSE}

# Set root directory
knitr::opts_knit$set( root.dir = '~/Documents/GitHub/DEG_comparison//' )

colorize <- function( x, color ) {
  if ( knitr::is_latex_output() ) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if ( knitr::is_github_output() ) {
    sprintf( "<span style='color: %s;'>%s</span>", color,
      x)
  } else x
}

# Set bash code chunks to use bash_profile
knitr::opts_chunk$set( engine.opts = list( bash = "-l" ) )

```

```{r, results = FALSE, message = FALSE, warning = FALSE}

# Load packages
library( DESeq2 )
library( edgeR )
library( EBSeq )
library( tidyverse )
library( ape )
library( vegan )
library( GGally )
library( arrayQualityMetrics )
library( rgl )
library( dplyr )
library( adegenet )

```

Read counts were produced by RSEM, mapped to a *de novo* transcriptome assembly for the Antarctic pteropod *Limacina helicina antarctica*.

#Features of popular DGE packages
| Program | Distribution | Dispersal | Random eff. | Continuous var. | Interactive eff. |
| :--- | :--- | :--- | :--- | :--- | :--- |
| EBSeq | Negative binomial | ? | ✖ | ✖ | ✖ |
| edgeR | Negative binomial | Avg., trended, tagwise, and Bayesian shrinkage options | ✔ |  ✔ |  ✔ |  ✔ | 
| DESeq2 | Negative binomial | Avg., trended, tagwise, and shrinkage options, | ✔ | ✔ | ✔|
| limma-voom | Mean-variance estimate | Empirical Bayes smooth | ✔ | ✔ |  ✔|  

#Filter and visualize read counts

```{r, message = FALSE, warning = FALSE}

# Read in matrix of RSEM expected read counts
data <- read.delim( "Input_data/expected_counts.matrix", sep = "\t", header = T, row.names = 1 )

# Peak at data to check that it looks okay
head( data )

# Name experimental samples: names correspond to pCO2 treatment (300, 600, 900) + days (12 h2 vs 7 days) + replicate ID
colnames( data ) <- c( "300.7.a", "300.7.b", "300.7.c","300.12.a", "300.12.b", "300.12.c", "600.7.a",
                       "900.7.b", "900.7.c", "900.12.a", "900.12.b", "900.12.c", "600.7.a", "600.7.b",
                       "600.7.c", "600.12.a", "600.12.b", "600.12.c")

# Create 'targets' and 'Group dataframe, expressing experimental variables for DEG analysis 
pCO2 <- as.numeric( c( 255, 255, 255, 255, 255, 255,
                       530, 530, 530, 530, 530, 530,
                       918, 918, 918, 918, 918, 918 ) )

treatment <- c( "B", "B", "B", "B", "B", "B",
                "R", "R", "R", "R", "R", "R",
                "Y", "Y", "Y", "Y", "Y", "Y" )

day <- as.numeric( c( 7, 7, 7, .5, .5, .5,
                      7, 7, 7, .5, .5, .5,
                      7, 7, 7, .5, .5, .5 ) )

targets <- data.frame( pCO2, day, treatment )
targets$grouping <- paste( targets$pCO2, targets$day, sep = "." )

Group <- factor( paste( targets$day, targets$pCO2, sep = "_" ) )
cbind( targets, Group = Group )

# Data must be rounded to nearest integer in order to be fit for negative binomial distribution
data_input <- round( data )

# Peak at rounded data
head( data_input )

# Plot distribution of unfiltered read counts across all samples 
ggplot( data = data.frame( rowMeans( data_input ) ),
        aes( x = rowMeans.data_input. ) ) +
  geom_density( fill = "grey" ) +
  xlim( 0, 500 ) +
  theme_classic() +
  labs( title = "Distribution of unfiltered reads" ) +
  labs( y = "Density", x = "Unfiltered read counts", title = "Read count distribution" )

```

##MDS plot visualizing mutliple factors

```{r, message = FALSE, warning = FALSE}

# Make a DGEList object for edgeR
y <- DGEList( counts = data_input, remove.zeros = TRUE )

#Let's remove samples with less then 0.5 cpm (this is ~10 counts in the count file) in fewer then 9/12 samples
keep <- rowSums( cpm( y ) > .5 ) >= 9

table( keep )

# Set keep.lib.sizes = F and recalculate library sizes after filtering
y <- y[ keep, keep.lib.sizes = FALSE ]

y <- calcNormFactors( y )

# Calculate logCPM
df_log <- cpm( y, log = TRUE, prior.count = 2 )

# Export pcoa loadings
dds.pcoa = pcoa( vegdist( t( df_log <- cpm( y, log = TRUE, prior.count = 2 ) ),
                          method = "euclidean") / 1000 )

# Create df of MDS vector loading
scores <- dds.pcoa$vectors

## Plot pcoa loadings of each sample, groouped by time point and pCO2 treatment

# Calculate % variation explained by each eigenvector
percent <- dds.pcoa$values$Eigenvalues
cumulative_percent_variance <- ( percent / sum( percent ) ) * 100

# Prepare information for pcoa plot, then plot
color <- c( "steelblue1", "tomato1", "goldenrod1")
par( mfrow = c( 1, 1 ) )
plot( scores[ , 1 ], scores[ , 2 ],
      cex=.5, cex.axis=1, cex.lab = 1.25,
      xlab = paste( "PC1, ", round( cumulative_percent_variance[ 1 ], 2 ), "%" ), 
      ylab = paste( "PC2, ", round( cumulative_percent_variance[ 2 ], 2 ), "%" ) )

# Add visual groupings to pcoa plot
ordihull( scores, as.factor(targets$treatment ), 
          border = NULL, lty = 2, lwd = .5, label = F,
          col = color, draw = "polygon", alpha = 100, cex = .5 )

ordispider( scores,as.factor( targets$grouping ),label = F ) # Vectors connecting samples in same pCO2 x time group

ordilabel( scores, cex = 0.5) # Label sample IDs

logCPM.pca <- prcomp( t ( df_log ) )
logCPM.pca.proportionvariances <- ( ( logCPM.pca$sdev ^ 2 ) / ( sum( logCPM.pca$sdev ^ 2 ) ) ) * 100


## Do treatment groups fully segregate? Wrap samples by pCO2 x time, not just pCO2
# Replot using logCPM.pca
plot( logCPM.pca$x, type = "n", main = NA, xlab = paste( "PC1, ", round( logCPM.pca.proportionvariances[ 1 ], 2 ), "%" ), ylab = paste( "PC2, ", round( logCPM.pca.proportionvariances[ 2 ], 2 ), "%" ) )

points( logCPM.pca$x, col = "black", pch = 16, cex = 1 )
colors2 <- c( "steelblue1", "dodgerblue2", "tomato1", "coral", "goldenrod1", "goldenrod3" )

ordihull( logCPM.pca$x, targets$grouping, 
          border = NULL, lty = 2, lwd = .5, 
          col = colors2, draw = "polygon", 
          alpha = 75,cex = .5, label = T )

```

#Interactive effects

##Interactive effects: edgeR

```{r, message = FALSE, warning = FALSE}

# Fit multifactoria design matrix
design_multi <- model.matrix( ~1 + pCO2 + pCO2:day ) #Generate multivariate edgeR glm

# Ensure that design matrix looks correct
colnames( design_multi )

# Estimate dispersion coefficients
y1 <- estimateDisp( y, robust = TRUE ) # Estimate mean dispersal

# Plot tagwise dispersal and impose w/ mean dispersal and trendline
plotBCV( y1 ) 

# Fit quasi-likelihood, neg binom linear regression
multi_fit <- glmQLFit( y1, design_multi ) # Fit multivariate model to counts
plotQLDisp( multi_fit, col.shrunk = "red", col.raw = "black", col.trend = NULL )

# Test for effect of pCO2
tr_pCO2 <- glmQLFTest( multi_fit, coef = 2, contrast = NULL, poisson.bound = FALSE ) # Estimate significant DEGs

is.de_tr_pCO2 <- decideTestsDGE( tr_pCO2, adjust.method = "fdr", p.value = 0.05 ) # Make contrasts

summary( is.de_tr_pCO2 )

plotMD( tr_pCO2 )

# Interaction
tr_int <- glmQLFTest( multi_fit, coef = 2, poisson.bound = FALSE ) # Estimate significant DEGs

is.de_int <- decideTestsDGE( tr_int, adjust.method = "fdr", p.value = 0.05 ) # Make contrasts

summary( is.de_int )

plotMD( tr_int )

# Check residuals
edgeR_res <- residuals( multi_fit, type = "pearson" )
head( edgeR_res )

```

##Interactive effects: limma-voom

```{r, message = FALSE, warning = FALSE}

# Perform voom transformation
voom <- voom( y, design_multi, plot = T )

# Fit using voom
lm_voom_fit <- lmFit( voom, design_multi )

# Create a contrast across continuous pCO2 variable
cont_pCO2 <- contrasts.fit( lm_voom_fit, coef = "pCO2" )

# Create a contrast across interaction etween continuous pCO2 and time variables
cont_pCO2_day <- contrasts.fit( lm_voom_fit, coef = "pCO2:day" )

# Perform empirical Bayes smoothing of standard errors
lm_voom_fit <- eBayes( lm_voom_fit )

# Output test statistics
pCO2_results <- topTable( lm_voom_fit, coef = "pCO2", adjust.method="fdr", n = Inf )
pCO2_day_results <- topTable( lm_voom_fit, coef = "pCO2:day", adjust.method="fdr", n = Inf )

# How many DEG are associated with pCO2 and pCO2:day?
length( which( pCO2_results$adj.P.Val < 0.05 & abs( pCO2_results$logFC ) > ( 4 / 600 ) ) ) # number of DE genes = 7091
length( which( pCO2_results$adj.P.Val < 0.05  ) ) # number of DE genes

length( which( pCO2_day_results$adj.P.Val < 0.05 & 
                 abs( pCO2_day_results$logFC ) > ( 4 / 600 ) ) ) # number of DE genes = 7091
length( which( pCO2_day_results$adj.P.Val < 0.05  ) ) # number of DE genes

```

##Interactive effects: DESeq2

In this current draft, it appears that fitting the interaction term ~ pCO2:day ONLY, rather than adding pCO2 + day + ..., results in the strongest correlations with voom and edgeR interaction stats. I am currently figuring out why this is.

As such, the DESeq2 code below only fits the interaction term to the read count data.

```{r, echo = FALSE}

gcounts <- as.data.frame( data_input )

totalCounts <- colSums( gcounts )

### REMOVE GENES WITH LOW MEAN COUNTS ###

# Make a DGEList object for edgeR
y <- DGEList( counts = data_input, remove.zeros = TRUE )

# Let's remove samples with less then 0.5 cpm (this is ~10 counts in the count file) in fewer then 9/12 samples
keep_g <- rowSums( cpm( gcounts ) > .5 ) >= 9

table( keep_g )

# Set keep.lib.sizes = F and recalculate library sizes after filtering
#gcounts <- gcounts[ keep_g, keep.lib.sizes = FALSE ]

### BUILD A DATAFRAME ASSOCIATING SAMPLE NAMESWITH TREATMENT CONDITIONS ###
targets

### WALD TEST - FULL MODEL ###

dds <- DESeqDataSetFromMatrix( gcounts,
                               colData = targets,
                               design = formula( ~ 1 + pCO2 + day : pCO2 ) )

rld <- rlog( dds )
rld.df <- assay( rld )

# Wald test for pCO2:day
dds_int <- DESeq( dds, minReplicatesForReplace = Inf )

design <- design( dds_int )

DESeq2_int_result_names <- resultsNames( dds_int )

DESeq2_int_results <- results( dds_int, name = "pCO2.day" )

```

##Comparing test statistics: interactive effects

```{r, message = FALSE, warning = FALSE}

# Merge logFC and pval data from each program
voom_edgeR_deseq_int_comp <- merge( 
  merge(
    data.frame( geneid = row.names( pCO2_day_results ),
                voom_logFC = pCO2_day_results$logFC,
                voom_pval = pCO2_day_results$P.Value ),
    data.frame( geneid = row.names( tr_int$table ),
                edgeR_logFC = -( tr_int$table$logFC ), #negate logFC because of syntax differences
                edgeR_pval = tr_int$table$PValue ), 
    by = "geneid" ),
  data.frame( geneid = row.names( DESeq2_int_results ),
              DESeq2_logFC = DESeq2_int_results$log2FoldChange,
              DESeq2_pval = DESeq2_int_results$pvalue ),
  by = "geneid" )

# Create neg log pvalues
voom_edgeR_deseq_int_comp$voom_neglogp <- -log( voom_edgeR_deseq_int_comp$voom_pval )
voom_edgeR_deseq_int_comp$edgeR_neglogp <- -log( voom_edgeR_deseq_int_comp$edgeR_pval )
voom_edgeR_deseq_int_comp$DESeq2_neglogp <- -log( voom_edgeR_deseq_int_comp$DESeq2_pval )

# Correlation matrix of pvalues
pval_pairs <- ggpairs( data = voom_edgeR_deseq_int_comp,
                       columns = c( 8, 9, 10 ),
                       mapping = aes( alpha = 0.001 ) ) +
  labs( title = "Correlation matrix: interaction p-values" )

pval_pairs

# Create neg log pvalues
voom_edgeR_deseq_int_comp$voom_neglogp <- -log( voom_edgeR_deseq_int_comp$voom_pval )
voom_edgeR_deseq_int_comp$edgeR_neglogp <- -log( voom_edgeR_deseq_int_comp$edgeR_pval )
voom_edgeR_deseq_int_comp$DESeq2_neglogp <- -log( voom_edgeR_deseq_int_comp$DESeq2_pval )

# Correlation matrix of logFC's
logFC_pairs <- ggpairs( data = voom_edgeR_deseq_int_comp,
                       columns = c( 2, 4, 6 ),
                       mapping = aes( alpha = 0.001 ) ) +
  labs( title = "Correlation matrix: interaction logFC's" )

logFC_pairs

# Correlation of logFC
ggplot( data = voom_edgeR_deseq_int_comp,
        aes( x = voom_logFC, y = edgeR_logFC ) ) +
  geom_hex( bins = 100,
            aes(fill = stat( log( count ) ) ) ) +
  theme_classic() +
  scale_fill_viridis_c() +
  geom_smooth( method = "lm", color = "red", lty = 2 ) +
  labs( title = "Interactions: edgeR vs. limma-voom logFC's", 
        x = "limma-voom logFC",
        y = "edgeR logFC" )

# Correlations between pvals
ggplot( data = voom_edgeR_deseq_int_comp,
        aes( x = -log( voom_pval ), y = -log( edgeR_pval ) ) ) +
  geom_hex( bins = 100,
            aes(fill = stat( log( count ) ) ) ) +
  theme_classic() +
  scale_fill_viridis_c() +
  geom_smooth( method = "lm", color = "red", lty = 2 ) +
  labs( title = "Interactions: edgeR vs. limma-voom p-values", 
        x = "limma-voom pval",
        y = "edgeR pval" )

# Correlation of logFC: edgeR vs DESeq2 
ggplot( data = voom_edgeR_deseq_int_comp,
        aes( x = DESeq2_logFC, y = edgeR_logFC ) ) +
  geom_hex( bins = 100,
            aes(fill = stat( log( count ) ) ) ) +
  theme_classic() +
  scale_fill_viridis_c() +
  geom_smooth( method = "lm", color = "red", lty = 2 ) +
  labs( title = "Interactions: edgeR vs. DESeq2 logFC's", 
        x = "DESeq2 logFC",
        y = "edgeR logFC" )

# Correlation of logFC: edgeR vs DESeq2 
ggplot( data = voom_edgeR_deseq_int_comp,
        aes( x = -log( DESeq2_pval ), y = -log( edgeR_pval ) ) ) +
  geom_hex( bins = 100,
            aes(fill = stat( log( count ) ) ) ) +
  xlim( values = c( 0, 20 ) ) +
  theme_classic() +
  scale_fill_viridis_c() +
  geom_smooth( method = "lm", color = "red", lty = 2 ) +
  labs( title = "Interactions: edgeR vs. DESeq2 p-values", 
        x = "DESeq2 logFC",
        y = "edgeR logFC" )

```

#Random Effects: voom 

We will skip edgeR and DESeq2 since they cannot fit random effects

```{r}

# Fit multifactoria design matrix
design_rand <- model.matrix( ~1 + pCO2 + ( 1 | day ) ) #Generate multivariate edgeR glm

# Perform voom transformation
voom_rand <- voom( y, design_rand, plot = T )

# Fit using voom
lm_voom_fit_rand <- lmFit( voom_rand, design_rand )

# Create a contrast across continuous pCO2 variable
cont_rand_day <- contrasts.fit( lm_voom_fit_rand, coef = "pCO2" )

# Perform empirical Bayes smoothing of standard errors
lm_voom_fit_rand <- eBayes( lm_voom_fit_rand )

# Output test statistics
rand_results <- topTable( lm_voom_fit_rand, coef = "pCO2", adjust.method = "fdr", n = Inf )

# How many DEG are associated with pCO2 and pCO2:day?
length( which( rand_results$adj.P.Val < 0.05 & abs( rand_results$logFC ) > ( 4 / 600 ) ) ) # number of DE genes = 7091
length( which( rand_results$adj.P.Val < 0.05  ) ) # number of DE genes

length( which( rand_results$adj.P.Val < 0.05 & 
                 abs( rand_results$logFC ) > ( 4 / 600 ) ) ) # number of DE genes = 7091
length( which( rand_results$adj.P.Val < 0.05  ) ) # number of DE genes

```

Random slopes: to our knowledge, no DESeq package permits the fitting of random slopes

What we want to test whether the effect of *p*CO$_{2}$ on expression varies by time, treating time as a random effect with different intercepts but a \beta parameter?

# GO enrichment 
Gene ontology (GO) are broad categories of gene function and processes that can help reveal higher level patterns in gene expression (and other data). To perform this analysis you will need an annotation file that maps your transcripts to their appropriate GO annotations. Several programs are available for GO enrichment analyses. We will cover a versatile option: GO MWU (Man-Whitney Un-ranked) which uses a simple ranking analyses to determine if certain GO categories are over represented among a list of ranked gene. These can be ranked based on log-fold change or p values, as well as a few other variable such as WGCNA eigen-gene module membership strength. See below for a description of WGCNA and its uses.

## GO_MWU
The GO_MWU R scripts (https://github.com/z0on/GO_MWU) were written and are maintained by Dr. Mikhail Matz. Please refer to the link above for the latest instructions in addition to the details below.   

To conduct a GO_MWU analysis you will need three files: 
1. A go.obo database. This can be downloaded from the gene ontology server: http://geneontology.org/docs/download-ontology/. *Always note which database version you use for future data reproducibility purposes.* 

2. A *tab-delimited* annotation file that lists your genes/isoform/contig IDs and their associated GO term IDs.Multiple GO terms should be separated by a semicolon. Genes/isoforms/contigs without annotations should be labeled 'unknown' if you would like to include these in the analyses. If your reference has multiple isoforms per gene and these are not labeled differently in your GO annotation file or if you collapsed transcript counts at a level higher than the individual isoforms you'll have ensure this file has unique genes/isoform/contig IDs. One way of doing this is using the nrify_GOtable.pl script provided with GO_MWU, however, if you do so ensure that you measure of interest file gene/isoform/contig IDs match the ones that are in this file.

3. A comma-separated file (with a header line) listing your genes/isoform/contig IDs and its measure of interest such as log-fold change, p value, etc. There are several choices for the measure of interest here: 
  A. Binary 1/0s. This analysis data using Fisher's exact test and gives you GO terms that may be enriched among the genes/isoforms/contigs of interest (those designated with 1). This is one way of analyze a category of genes/isoform/contigs that may be of interest for a specific reason (e.g. show evidence of selection or high mutation, etc.)
  B. Os and kME value (between 0 and 1 for WGCNA membership score)
  C. Signed negative log p-values. These measures are negative decimal logarithms of the *raw (uncorrected)* p-value for each gene, multiplied by -1 if the gene was down-regulated. As a result, highly significant up-regulated genes get highly positive values, and highly significant down-regulated genes get highly negative values. This is the format in which the GO_MWU sample data comes in. An additional note from the GO_MWU page says: "In read-based gene expression analysis (RNA-seq, TagSeq) p-values may be biased towards highly abundant genes, especially when the read depth is low. This may result in the corresponding GO bias. Use log2-fold changes to avoid this." 
  D. Log2 fold-change 
  E. Other measure such as dN/dS ratio


You'll need to download the GO_MWU set of scripts into the directory that contains your data. 
*Tip:* Put the scripts in the actual script files in the same directory as your data, giving the scripts relative or even absolute paths to your files can sometimes cause errors. 

Then you'll first have to run the GO_MWU stats script. This actually calculates the enrichment. Under the goDivision you can input: "BP" for Biological Processes, "MF" for Molecular Functions, or "CC" for cellular components. BP analyses tend to take the longest to run so if you're looking for results faster run MF or CC first. 

Then there are a few other parameters that can be modified: 
 - "largest" ranges from 0 to 1 and refers to the fraction of the overall number of genes. If a GO category contains more than that fraction of all genes/isoforms/contigs it will be ignored. This serves to remove GO categories that are too broad/common to be informative. The default value is 0.1 and should work well for most analyses in marine omics. If you annotation are of extremely high quality you may consider increasing the number, and vice versa for poorly annotated references. 
 - "smallest" is an integer value and specifies the minimum number of genes/isoforms/contigs that a GO category should contain in order to be included. The default value is 5. This serves to remove low count GO categories that may not be informative. If you GO results contain more terms than can be easily visiualized, consider increasing this number. 
 - "clusterCutHeight" ranges between 0 and 1 and specifies the cutoff in hierarchical clustering relatedness that is used to merge GO term categories. This serves to simplify GO terms and elimate multiple displays of highly similar GO terms, e.g. "regulation of cell cycle" and "cell cycle" for instance. The default value is 0.25, implying that a GO terms will be merged if the most dissimilar two of them share >75% of genes included in the smaller of the two. If your GO trees are too crowded for visualization you can increase this value to merge more GO terms. The GO term label retained will be for the largest of the two groups (the one with the most genes).
 - "Alternative" refers to whether you want a one or two-tailed test. The default is two tailed. You can specify 'g' or 'l' for a greater/lesser than one-tailed test. 
 - "Module" is a boolean and is set to FALSE as default. Change to TRUE if you are analyzing a WGCNA module. If so your input values of interest are 0 and kME scores you should also set "Alternative" to g. If your module input values are only 0/1s leave as Module = TRUE and do not change "Alternative". 


```{r}
input="expected_counts.matrix"
goAnnotations="Transcriptome_GO_forMWU.tab" # two-column, tab-delimited, one line per gene, multiple GO terms separated by semicolon. 
goDatabase="go.obo"
#download from http://www.geneontology.org/GO.downloads.ontology.shtml
goDivision="BP" # either MF, or BP, or CC
source("gomwu.functions.R")

#Biological Processes
gomwuStats(input, goDatabase, goAnnotations, goDivision,
           perlPath="perl", # replace with full path to perl executable if it is not in your system's PATH already
           largest=0.1,  # a GO category will not be considered if it contains more than this fraction of the total number of genes
           smallest=5,   # a GO category should contain at least this many genes to be considered
           clusterCutHeight=0.25, # threshold for merging similar (gene-sharing) terms. See README for details.
#	Alternative="g" # by default the MWU test is two-tailed; specify "g" or "l" of you want to test for "greater" or "less" instead. 
#	Module=TRUE,Alternative="g" # un-remark this if you are analyzing a SIGNED WGCNA module (values: 0 for not in module genes, kME for in-module genes). In the call to gomwuPlot below, specify absValue=0.001 (count number of "good genes" that fall into the module)
#	Module=TRUE # un-remark this if you are analyzing an UNSIGNED WGCNA module 
)
# do not continue if the printout shows that no GO terms pass 10% FDR.
```








